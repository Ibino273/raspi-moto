# ğŸï¸ Moto Scraper V2 - Raspberry Pi

Sistema completo per scraping automatico di annunci moto da Subito.it, salvataggio su Supabase e visualizzazione su dashboard web.

## ğŸ“‹ Indice

- [Caratteristiche](#caratteristiche)
- [Requisiti](#requisiti)
- [Installazione](#installazione)
- [Configurazione](#configurazione)
- [Utilizzo](#utilizzo)
- [Struttura Database](#struttura-database)
- [Deployment Frontend](#deployment-frontend)
- [Cron Job](#cron-job)
- [Troubleshooting](#troubleshooting)

## âœ¨ Caratteristiche

- âœ… **Scraping robusto** con retry automatico e gestione errori
- âœ… **Deduplicazione intelligente** - aggiorna solo annunci modificati
- âœ… **Logging avanzato** con Winston
- âœ… **User-Agent rotation** per evitare blocchi
- âœ… **Rate limiting** con delay randomici
- âœ… **Configurazione flessibile** tramite variabili ambiente
- âœ… **Ottimizzato per Raspberry Pi** (headless, basso consumo)
- âœ… **Statistiche dettagliate** su ogni esecuzione

## ğŸ“¦ Requisiti

- Raspberry Pi (3B+ o superiore)
- Raspbian OS (Bullseye o Bookworm)
- Node.js 18.x
- Account Supabase (gratuito)
- Minimo 2GB RAM
- Connessione internet stabile

## ğŸš€ Installazione

### 1. Clona o trasferisci il repository

```bash
cd ~
git clone https://github.com/tuo-username/moto-scraper-v2.git
cd moto-scraper-v2
```

### 2. Esegui lo script di setup

```bash
chmod +x setup.sh
./setup.sh
```

Lo script installerÃ  automaticamente:
- Node.js 18.x
- Dipendenze npm
- Chromium per Playwright
- Directory e file necessari

## âš™ï¸ Configurazione

### 1. Configura Supabase

1. Vai su [supabase.com](https://supabase.com) e crea un nuovo progetto
2. Vai su **Settings** â†’ **API**
3. Copia:
   - `URL` del progetto
   - `service_role` key (secret)

### 2. Configura le variabili ambiente

```bash
cp .env.example .env
nano .env
```

Inserisci i tuoi valori:

```env
SUPABASE_URL=https://xxxxxxxxxxxx.supabase.co
SUPABASE_SERVICE_ROLE_KEY=eyJhbGc....
MAX_PAGES=5
MAX_LISTINGS_PER_PAGE=30
LOG_LEVEL=info
```

### 3. Crea la tabella nel database

Vai su Supabase â†’ **SQL Editor** ed esegui lo script `database/schema.sql`.

## ğŸ¯ Utilizzo

### Test manuale

```bash
npm run scrape
```

### Monitora i log

```bash
# Log in tempo reale
tail -f logs/scraper.log

# Ultimi 50 log
tail -50 logs/scraper.log

# Cerca errori
grep "ERROR" logs/scraper.log
```

### Statistiche

Lo scraper stampa statistiche dettagliate al termine:

```
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
ğŸ“Š STATISTICHE SCRAPING
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
â±ï¸  Durata: 145 secondi
ğŸ“„ Pagine scrapate: 5
ğŸ” Annunci trovati: 150
âœ… Annunci processati: 147
â• Nuovi inseriti: 23
âœï¸  Aggiornati: 8
â­ï¸  Saltati: 116
âŒ Errori: 3
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
```

## ğŸ—„ï¸ Struttura Database

La tabella `moto_listings` su Supabase ha questa struttura:

```sql
CREATE TABLE moto_listings (
  id BIGSERIAL PRIMARY KEY,
  created_at TIMESTAMPTZ DEFAULT NOW(),
  updated_at TIMESTAMPTZ DEFAULT NOW(),
  
  -- Informazioni veicolo
  marca TEXT,
  modello TEXT,
  anno INTEGER,
  km INTEGER,
  cilindrata INTEGER,
  versione TEXT,
  tipo_veicolo TEXT,
  
  -- Annuncio
  prezzo NUMERIC,
  likes INTEGER DEFAULT 0,
  citta TEXT,
  data_pubblicazione TIMESTAMPTZ,
  descrizione TEXT,
  link_annuncio TEXT UNIQUE NOT NULL,
  
  -- Venditore
  venditore TEXT
);

-- Indici per performance
CREATE INDEX idx_marca_modello ON moto_listings(marca, modello);
CREATE INDEX idx_prezzo ON moto_listings(prezzo);
CREATE INDEX idx_anno ON moto_listings(anno);
CREATE INDEX idx_data_pubblicazione ON moto_listings(data_pubblicazione DESC);
CREATE INDEX idx_link_annuncio ON moto_listings(link_annuncio);
```

## â° Cron Job

Per esecuzione automatica giornaliera:

```bash
crontab -e
```

Aggiungi una di queste righe:

```bash
# Ogni giorno alle 7:00
0 7 * * * /home/pi/moto-scraper-v2/run-scraper.sh

# Ogni 6 ore
0 */6 * * * /home/pi/moto-scraper-v2/run-scraper.sh

# Due volte al giorno (7:00 e 19:00)
0 7,19 * * * /home/pi/moto-scraper-v2/run-scraper.sh
```

Verifica il cron:
```bash
crontab -l
```

Monitora log cron:
```bash
tail -f logs/cron.log
```

## ğŸŒ Deployment Frontend

Il frontend React/Next.js puÃ² essere deployato su Vercel.

Vedi `/frontend/README.md` per istruzioni dettagliate.

## ğŸ”§ Troubleshooting

### Errore: "SUPABASE_URL non configurata"

```bash
# Verifica che .env esista e sia configurato
cat .env
```

### Errore: "Impossibile connettersi al database"

- Verifica le credenziali Supabase
- Controlla che la tabella `moto_listings` esista
- Verifica la connessione internet

### Browser non si avvia

```bash
# Reinstalla dipendenze Playwright
npx playwright install-deps chromium
```

### Memoria insufficiente

Riduci il numero di pagine/listing nel `.env`:

```env
MAX_PAGES=3
MAX_LISTINGS_PER_PAGE=20
```

### Cookie banner non gestito

Il parser tenta 3 metodi diversi. Se falliscono tutti:
1. Controlla i log per errori specifici
2. Verifica che il sito non sia stato modificato
3. Apri un issue su GitHub

## ğŸ“Š Monitoraggio Performance

### RAM Usage

```bash
free -h
```

### CPU Usage

```bash
top -n 1 | grep node
```

### Disk Space

```bash
df -h
```

### Rotazione Log

I log vengono automaticamente ruotati (max 5 file da 5MB).

Per pulizia manuale:
```bash
rm logs/scraper.log.*
```

## ğŸ¤ Contribuire

1. Fork del progetto
2. Crea un branch (`git checkout -b feature/nuova-funzione`)
3. Commit delle modifiche (`git commit -am 'Aggiunge nuova funzione'`)
4. Push al branch (`git push origin feature/nuova-funzione`)
5. Apri una Pull Request

## ğŸ“ Changelog

### v2.0.0 (2026-01-15)
- âœ¨ Riscrittura completa con moduli ES6
- âœ¨ Logging avanzato con Winston
- âœ¨ Gestione errori robusta con retry
- âœ¨ Deduplicazione intelligente
- âœ¨ Parser modulare e manutenibile
- âœ¨ Statistiche dettagliate
- âœ¨ Ottimizzazioni per Raspberry Pi

### v1.0.0
- ğŸ‰ Release iniziale

## ğŸ“„ Licenza

MIT

## ğŸ‘¨â€ğŸ’» Autore

Creato con â¤ï¸ per il mondo delle moto
